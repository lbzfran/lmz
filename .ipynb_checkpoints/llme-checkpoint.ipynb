{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"LM based on Me\"\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: anyio==4.8.0 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 1)) (4.8.0)\n",
      "Requirement already satisfied: argon2-cffi==23.1.0 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 2)) (23.1.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings==21.2.0 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 3)) (21.2.0)\n",
      "Requirement already satisfied: arrow==1.3.0 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: asttokens==3.0.0 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 5)) (3.0.0)\n",
      "Requirement already satisfied: async-lru==2.0.4 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 6)) (2.0.4)\n",
      "Requirement already satisfied: attrs==25.1.0 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 7)) (25.1.0)\n",
      "Requirement already satisfied: babel==2.17.0 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 8)) (2.17.0)\n",
      "Requirement already satisfied: beautifulsoup4==4.13.3 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 9)) (4.13.3)\n",
      "Requirement already satisfied: bleach==6.2.0 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 10)) (6.2.0)\n",
      "Requirement already satisfied: certifi==2025.1.31 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 11)) (2025.1.31)\n",
      "Requirement already satisfied: cffi==1.17.1 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 12)) (1.17.1)\n",
      "Requirement already satisfied: charset-normalizer==3.4.1 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 13)) (3.4.1)\n",
      "Requirement already satisfied: colorama==0.4.6 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 14)) (0.4.6)\n",
      "Requirement already satisfied: comm==0.2.2 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 15)) (0.2.2)\n",
      "Requirement already satisfied: debugpy==1.8.13 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 16)) (1.8.13)\n",
      "Requirement already satisfied: decorator==5.2.1 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 17)) (5.2.1)\n",
      "Requirement already satisfied: defusedxml==0.7.1 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 18)) (0.7.1)\n",
      "Requirement already satisfied: executing==2.2.0 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 19)) (2.2.0)\n",
      "Requirement already satisfied: fastjsonschema==2.21.1 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 20)) (2.21.1)\n",
      "Requirement already satisfied: filelock==3.17.0 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 21)) (3.17.0)\n",
      "Requirement already satisfied: fqdn==1.5.1 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 22)) (1.5.1)\n",
      "Requirement already satisfied: fsspec==2025.3.0 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 23)) (2025.3.0)\n",
      "Requirement already satisfied: h11==0.14.0 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 24)) (0.14.0)\n",
      "Requirement already satisfied: httpcore==1.0.7 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 25)) (1.0.7)\n",
      "Requirement already satisfied: httpx==0.28.1 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 26)) (0.28.1)\n",
      "Requirement already satisfied: idna==3.10 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 27)) (3.10)\n",
      "Requirement already satisfied: ipykernel==6.29.5 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 28)) (6.29.5)\n",
      "Requirement already satisfied: ipython==9.0.2 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 29)) (9.0.2)\n",
      "Requirement already satisfied: ipython_pygments_lexers==1.1.1 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 30)) (1.1.1)\n",
      "Requirement already satisfied: ipywidgets==8.1.5 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 31)) (8.1.5)\n",
      "Requirement already satisfied: isoduration==20.11.0 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 32)) (20.11.0)\n",
      "Requirement already satisfied: jedi==0.19.2 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 33)) (0.19.2)\n",
      "Requirement already satisfied: Jinja2==3.1.6 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 34)) (3.1.6)\n",
      "Requirement already satisfied: json5==0.10.0 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 35)) (0.10.0)\n",
      "Requirement already satisfied: jsonpointer==3.0.0 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 36)) (3.0.0)\n",
      "Requirement already satisfied: jsonschema==4.23.0 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 37)) (4.23.0)\n",
      "Requirement already satisfied: jsonschema-specifications==2024.10.1 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 38)) (2024.10.1)\n",
      "Requirement already satisfied: jupyter==1.1.1 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 39)) (1.1.1)\n",
      "Requirement already satisfied: jupyter-console==6.6.3 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 40)) (6.6.3)\n",
      "Requirement already satisfied: jupyter-events==0.12.0 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 41)) (0.12.0)\n",
      "Requirement already satisfied: jupyter-lsp==2.2.5 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 42)) (2.2.5)\n",
      "Requirement already satisfied: jupyter_client==8.6.3 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 43)) (8.6.3)\n",
      "Requirement already satisfied: jupyter_core==5.7.2 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 44)) (5.7.2)\n",
      "Requirement already satisfied: jupyter_server==2.15.0 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 45)) (2.15.0)\n",
      "Requirement already satisfied: jupyter_server_terminals==0.5.3 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 46)) (0.5.3)\n",
      "Requirement already satisfied: jupyterlab==4.3.5 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 47)) (4.3.5)\n",
      "Requirement already satisfied: jupyterlab_pygments==0.3.0 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 48)) (0.3.0)\n",
      "Requirement already satisfied: jupyterlab_server==2.27.3 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 49)) (2.27.3)\n",
      "Requirement already satisfied: jupyterlab_widgets==3.0.13 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 50)) (3.0.13)\n",
      "Requirement already satisfied: MarkupSafe==3.0.2 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 51)) (3.0.2)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 52)) (0.1.7)\n",
      "Requirement already satisfied: mistune==3.1.2 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 53)) (3.1.2)\n",
      "Requirement already satisfied: mpmath==1.3.0 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 54)) (1.3.0)\n",
      "Requirement already satisfied: nbclient==0.10.2 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 55)) (0.10.2)\n",
      "Requirement already satisfied: nbconvert==7.16.6 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 56)) (7.16.6)\n",
      "Requirement already satisfied: nbformat==5.10.4 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 57)) (5.10.4)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 58)) (1.6.0)\n",
      "Requirement already satisfied: networkx==3.4.2 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 59)) (3.4.2)\n",
      "Requirement already satisfied: notebook==7.3.2 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 60)) (7.3.2)\n",
      "Requirement already satisfied: notebook_shim==0.2.4 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 61)) (0.2.4)\n",
      "Requirement already satisfied: numpy==2.2.3 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 62)) (2.2.3)\n",
      "Requirement already satisfied: overrides==7.7.0 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 63)) (7.7.0)\n",
      "Requirement already satisfied: packaging==24.2 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 64)) (24.2)\n",
      "Requirement already satisfied: pandas==2.2.3 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 65)) (2.2.3)\n",
      "Requirement already satisfied: pandocfilters==1.5.1 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 66)) (1.5.1)\n",
      "Requirement already satisfied: parso==0.8.4 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 67)) (0.8.4)\n",
      "Requirement already satisfied: pathlib==1.0.1 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 68)) (1.0.1)\n",
      "Requirement already satisfied: platformdirs==4.3.6 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 69)) (4.3.6)\n",
      "Requirement already satisfied: prometheus_client==0.21.1 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 70)) (0.21.1)\n",
      "Requirement already satisfied: prompt_toolkit==3.0.50 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 71)) (3.0.50)\n",
      "Requirement already satisfied: psutil==7.0.0 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 72)) (7.0.0)\n",
      "Requirement already satisfied: pure_eval==0.2.3 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 73)) (0.2.3)\n",
      "Requirement already satisfied: pycparser==2.22 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 74)) (2.22)\n",
      "Requirement already satisfied: Pygments==2.19.1 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 75)) (2.19.1)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 76)) (2.9.0.post0)\n",
      "Requirement already satisfied: python-json-logger==3.3.0 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 77)) (3.3.0)\n",
      "Requirement already satisfied: pytz==2025.1 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 78)) (2025.1)\n",
      "Requirement already satisfied: pywin32==308 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 79)) (308)\n",
      "Requirement already satisfied: pywinpty==2.0.15 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 80)) (2.0.15)\n",
      "Requirement already satisfied: PyYAML==6.0.2 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 81)) (6.0.2)\n",
      "Requirement already satisfied: pyzmq==26.2.1 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 82)) (26.2.1)\n",
      "Requirement already satisfied: referencing==0.36.2 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 83)) (0.36.2)\n",
      "Requirement already satisfied: regex==2024.11.6 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 84)) (2024.11.6)\n",
      "Requirement already satisfied: requests==2.32.3 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 85)) (2.32.3)\n",
      "Requirement already satisfied: rfc3339-validator==0.1.4 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 86)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator==0.1.1 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 87)) (0.1.1)\n",
      "Requirement already satisfied: rpds-py==0.23.1 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 88)) (0.23.1)\n",
      "Requirement already satisfied: Send2Trash==1.8.3 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 89)) (1.8.3)\n",
      "Requirement already satisfied: setuptools==75.9.1 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 90)) (75.9.1)\n",
      "Requirement already satisfied: six==1.17.0 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 91)) (1.17.0)\n",
      "Requirement already satisfied: sniffio==1.3.1 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 92)) (1.3.1)\n",
      "Requirement already satisfied: soupsieve==2.6 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 93)) (2.6)\n",
      "Requirement already satisfied: stack-data==0.6.3 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 94)) (0.6.3)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 95)) (1.13.1)\n",
      "Requirement already satisfied: terminado==0.18.1 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 96)) (0.18.1)\n",
      "Requirement already satisfied: tiktoken==0.9.0 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 97)) (0.9.0)\n",
      "Requirement already satisfied: tinycss2==1.4.0 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 98)) (1.4.0)\n",
      "Requirement already satisfied: torch==2.6.0 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 99)) (2.6.0)\n",
      "Requirement already satisfied: tornado==6.4.2 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 100)) (6.4.2)\n",
      "Requirement already satisfied: traitlets==5.14.3 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 101)) (5.14.3)\n",
      "Requirement already satisfied: types-python-dateutil==2.9.0.20241206 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 102)) (2.9.0.20241206)\n",
      "Requirement already satisfied: typing_extensions==4.12.2 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 103)) (4.12.2)\n",
      "Requirement already satisfied: tzdata==2025.1 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 104)) (2025.1)\n",
      "Requirement already satisfied: uri-template==1.3.0 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 105)) (1.3.0)\n",
      "Requirement already satisfied: urllib3==2.3.0 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 106)) (2.3.0)\n",
      "Requirement already satisfied: wcwidth==0.2.13 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 107)) (0.2.13)\n",
      "Requirement already satisfied: webcolors==24.11.1 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 108)) (24.11.1)\n",
      "Requirement already satisfied: webencodings==0.5.1 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 109)) (0.5.1)\n",
      "Requirement already satisfied: websocket-client==1.8.0 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 110)) (1.8.0)\n",
      "Requirement already satisfied: widgetsnbextension==4.0.13 in c:\\users\\scout\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 111)) (4.0.13)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import regex as re\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple, Dict\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e0ed10ce50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(36432)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_document(filepath: str) -> pd.DataFrame:\n",
    "\n",
    "    # put any filters here\n",
    "\n",
    "    lines = []\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    filtered_lines = []\n",
    "    for line in lines:\n",
    "        if (\n",
    "            \"ENTRY\" not in line and\n",
    "            \"CHAPTER\" not in line\n",
    "        ):\n",
    "            filtered_lines.append(line)\n",
    "\n",
    "    df = pd.DataFrame(filtered_lines)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have come to the conclusion.. That I have a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If I were to begin writing about these strange...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It happened during my foreign exchange at Japa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>At the very least, that's what I thought. No.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Though then again, how I came to bother her wa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  I have come to the conclusion.. That I have a ...\n",
       "1  If I were to begin writing about these strange...\n",
       "2  It happened during my foreign exchange at Japa...\n",
       "3  At the very least, that's what I thought. No.....\n",
       "4  Though then again, how I came to bother her wa..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_stories = {}\n",
    "data_directory = Path(\"./data\")\n",
    "\n",
    "for file in data_directory.glob(\"*.txt\"):\n",
    "    filename = file.stem\n",
    "    all_stories[filename] = read_document(file)\n",
    "\n",
    "all_stories[filename].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this simple code snippet, we are able to import as many text files\n",
    "as we want from our data directory, filter out lines as necessary, and\n",
    "convert them into a DataFrame.\n",
    "\n",
    "## Tokenizing the text\n",
    "\n",
    "This implementation will focus on using Byte Pair Encoding tokenization,\n",
    "which encodes a fixed size of tokens.\n",
    "It is a healthy balance between simply tokenizing per character, or\n",
    "tokenizing per word, which in either case may yield too little or too\n",
    "many tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of text_sequence: 47476\n"
     ]
    }
   ],
   "source": [
    "text_sequence = \"\"\n",
    "for story in all_stories.keys():\n",
    "    text_sequence += \" \".join(all_stories[story][0].values)\n",
    "\n",
    "print(f\"size of text_sequence: {len(text_sequence)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('./lib')\n",
    "from minbpe import BasicTokenizer\n",
    "from transformer.model import GPTLanguageModel\n",
    "\n",
    "tokenizer = BasicTokenizer()\n",
    "tokenizer.train(text_sequence, vocab_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at the token sequences now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: b'\\x00', 1: b'\\x01', 2: b'\\x02', 3: b'\\x03', 4: b'\\x04', 5: b'\\x05', 6: b'\\x06', 7: b'\\x07', 8: b'\\x08', 9: b'\\t', 10: b'\\n', 11: b'\\x0b', 12: b'\\x0c', 13: b'\\r', 14: b'\\x0e', 15: b'\\x0f', 16: b'\\x10', 17: b'\\x11', 18: b'\\x12', 19: b'\\x13', 20: b'\\x14', 21: b'\\x15', 22: b'\\x16', 23: b'\\x17', 24: b'\\x18', 25: b'\\x19', 26: b'\\x1a', 27: b'\\x1b', 28: b'\\x1c', 29: b'\\x1d', 30: b'\\x1e', 31: b'\\x1f', 32: b' ', 33: b'!', 34: b'\"', 35: b'#', 36: b'$', 37: b'%', 38: b'&', 39: b\"'\", 40: b'(', 41: b')', 42: b'*', 43: b'+', 44: b',', 45: b'-', 46: b'.', 47: b'/', 48: b'0', 49: b'1', 50: b'2', 51: b'3', 52: b'4', 53: b'5', 54: b'6', 55: b'7', 56: b'8', 57: b'9', 58: b':', 59: b';', 60: b'<', 61: b'=', 62: b'>', 63: b'?', 64: b'@', 65: b'A', 66: b'B', 67: b'C', 68: b'D', 69: b'E', 70: b'F', 71: b'G', 72: b'H', 73: b'I', 74: b'J', 75: b'K', 76: b'L', 77: b'M', 78: b'N', 79: b'O', 80: b'P', 81: b'Q', 82: b'R', 83: b'S', 84: b'T', 85: b'U', 86: b'V', 87: b'W', 88: b'X', 89: b'Y', 90: b'Z', 91: b'[', 92: b'\\\\', 93: b']', 94: b'^', 95: b'_', 96: b'`', 97: b'a', 98: b'b', 99: b'c', 100: b'd', 101: b'e', 102: b'f', 103: b'g', 104: b'h', 105: b'i', 106: b'j', 107: b'k', 108: b'l', 109: b'm', 110: b'n', 111: b'o', 112: b'p', 113: b'q', 114: b'r', 115: b's', 116: b't', 117: b'u', 118: b'v', 119: b'w', 120: b'x', 121: b'y', 122: b'z', 123: b'{', 124: b'|', 125: b'}', 126: b'~', 127: b'\\x7f', 128: b'\\x80', 129: b'\\x81', 130: b'\\x82', 131: b'\\x83', 132: b'\\x84', 133: b'\\x85', 134: b'\\x86', 135: b'\\x87', 136: b'\\x88', 137: b'\\x89', 138: b'\\x8a', 139: b'\\x8b', 140: b'\\x8c', 141: b'\\x8d', 142: b'\\x8e', 143: b'\\x8f', 144: b'\\x90', 145: b'\\x91', 146: b'\\x92', 147: b'\\x93', 148: b'\\x94', 149: b'\\x95', 150: b'\\x96', 151: b'\\x97', 152: b'\\x98', 153: b'\\x99', 154: b'\\x9a', 155: b'\\x9b', 156: b'\\x9c', 157: b'\\x9d', 158: b'\\x9e', 159: b'\\x9f', 160: b'\\xa0', 161: b'\\xa1', 162: b'\\xa2', 163: b'\\xa3', 164: b'\\xa4', 165: b'\\xa5', 166: b'\\xa6', 167: b'\\xa7', 168: b'\\xa8', 169: b'\\xa9', 170: b'\\xaa', 171: b'\\xab', 172: b'\\xac', 173: b'\\xad', 174: b'\\xae', 175: b'\\xaf', 176: b'\\xb0', 177: b'\\xb1', 178: b'\\xb2', 179: b'\\xb3', 180: b'\\xb4', 181: b'\\xb5', 182: b'\\xb6', 183: b'\\xb7', 184: b'\\xb8', 185: b'\\xb9', 186: b'\\xba', 187: b'\\xbb', 188: b'\\xbc', 189: b'\\xbd', 190: b'\\xbe', 191: b'\\xbf', 192: b'\\xc0', 193: b'\\xc1', 194: b'\\xc2', 195: b'\\xc3', 196: b'\\xc4', 197: b'\\xc5', 198: b'\\xc6', 199: b'\\xc7', 200: b'\\xc8', 201: b'\\xc9', 202: b'\\xca', 203: b'\\xcb', 204: b'\\xcc', 205: b'\\xcd', 206: b'\\xce', 207: b'\\xcf', 208: b'\\xd0', 209: b'\\xd1', 210: b'\\xd2', 211: b'\\xd3', 212: b'\\xd4', 213: b'\\xd5', 214: b'\\xd6', 215: b'\\xd7', 216: b'\\xd8', 217: b'\\xd9', 218: b'\\xda', 219: b'\\xdb', 220: b'\\xdc', 221: b'\\xdd', 222: b'\\xde', 223: b'\\xdf', 224: b'\\xe0', 225: b'\\xe1', 226: b'\\xe2', 227: b'\\xe3', 228: b'\\xe4', 229: b'\\xe5', 230: b'\\xe6', 231: b'\\xe7', 232: b'\\xe8', 233: b'\\xe9', 234: b'\\xea', 235: b'\\xeb', 236: b'\\xec', 237: b'\\xed', 238: b'\\xee', 239: b'\\xef', 240: b'\\xf0', 241: b'\\xf1', 242: b'\\xf2', 243: b'\\xf3', 244: b'\\xf4', 245: b'\\xf5', 246: b'\\xf6', 247: b'\\xf7', 248: b'\\xf8', 249: b'\\xf9', 250: b'\\xfa', 251: b'\\xfb', 252: b'\\xfc', 253: b'\\xfd', 254: b'\\xfe', 255: b'\\xff', 256: b'e ', 257: b't ', 258: b'th', 259: b'\\xe2\\x80', 260: b's ', 261: b'in', 262: b'd ', 263: b'er', 264: b'\\n ', 265: b', ', 266: b'y ', 267: b'ou', 268: b'. ', 269: b'o ', 270: b'an', 271: b'I ', 272: b'ing', 273: b'on', 274: b'\\xe2\\x80\\x99', 275: b'en', 276: b'ing ', 277: b'ha', 278: b'to ', 279: b'wa', 280: b'.\\n ', 281: b'the ', 282: b'al', 283: b'or', 284: b'ed ', 285: b'a ', 286: b'\\xe2\\x80\\x9c', 287: b'\\xe2\\x80\\x9d', 288: b'ar', 289: b'st', 290: b'\\xe2\\x80\\x9d\\n ', 291: b'f ', 292: b'er ', 293: b'me', 294: b'at', 295: b'ow', 296: b'at ', 297: b're', 298: b'it', 299: b'el', 300: b'me ', 301: b'..', 302: b'st ', 303: b'was ', 304: b'he ', 305: b'ly ', 306: b'it ', 307: b'\\xe2\\x80\\x99s ', 308: b'of ', 309: b'\\xe2\\x80\\x99t ', 310: b'ac', 311: b'oul', 312: b'is ', 313: b'that ', 314: b'gh', 315: b'li', 316: b'l ', 317: b've ', 318: b'and ', 319: b'ab', 320: b'se', 321: b'id', 322: b'.. ', 323: b'le', 324: b'be', 325: b'oo', 326: b'm ', 327: b'ic', 328: b'en ', 329: b'for', 330: b'ev', 331: b'my ', 332: b'ould ', 333: b'ke ', 334: b'you', 335: b'ion', 336: b'k ', 337: b'in ', 338: b'es', 339: b'ch', 340: b'hat ', 341: b'ut ', 342: b'ow ', 343: b'ro', 344: b'so', 345: b'\\xe2\\x80\\x9d\\n \\xe2\\x80\\x9c', 346: b'wh', 347: b'as ', 348: b'nd ', 349: b'no', 350: b'sa', 351: b', I ', 352: b'an ', 353: b'ri', 354: b'sh', 355: b'. I ', 356: b'I\\xe2\\x80\\x99', 357: b'ust ', 358: b'ur', 359: b'il', 360: b'n\\xe2\\x80\\x99t ', 361: b'out ', 362: b'ere ', 363: b'ag', 364: b'she ', 365: b'for ', 366: b'be ', 367: b'you ', 368: b', and ', 369: b'ed', 370: b'to', 371: b'this ', 372: b'ir', 373: b'like ', 374: b'di', 375: b'ough', 376: b', b', 377: b'pp', 378: b'ent', 379: b'? ', 380: b'just ', 381: b'one ', 382: b'n ', 383: b'. T', 384: b'se ', 385: b', but ', 386: b't\\xe2\\x80\\x99s ', 387: b'that', 388: b'con', 389: b'wi', 390: b'.\\n \\t', 391: b'le ', 392: b'ca', 393: b'her ', 394: b'And ', 395: b'up', 396: b'the', 397: b'co', 398: b'un', 399: b'ver', 400: b'mo', 401: b'th ', 402: b'\\xe2\\x80\\x9d\\n \\t', 403: b'on ', 404: b'act', 405: b'ma', 406: b'thing ', 407: b'her', 408: b'la', 409: b'ally ', 410: b'he', 411: b'on\\xe2\\x80\\x99t ', 412: b'um', 413: b'ed to ', 414: b'ti', 415: b'ly', 416: b'ep', 417: b'. I', 418: b'ex', 419: b'ent ', 420: b'ge', 421: b'some', 422: b'kn', 423: b'po', 424: b'es ', 425: b'oun', 426: b'king ', 427: b'I\\xe2\\x80\\x99m ', 428: b'lo', 429: b'!\\n ', 430: b'not ', 431: b'what ', 432: b'im', 433: b'ss', 434: b'ec', 435: b'have ', 436: b'ion ', 437: b'about ', 438: b'with ', 439: b'go', 440: b'so ', 441: b'--', 442: b'.\\xe2\\x80\\x9d\\n \\xe2\\x80\\x9c', 443: b'all ', 444: b'is', 445: b'if ', 446: b'ft', 447: b'would ', 448: b'ay', 449: b'ch ', 450: b'fro', 451: b'! ', 452: b'e, ', 453: b'ad', 454: b'.\\n \\xe2\\x80\\x9c', 455: b'though', 456: b'mu', 457: b'even ', 458: b'bo', 459: b'don\\xe2\\x80\\x99t ', 460: b'from ', 461: b'car', 462: b'gu', 463: b'I c', 464: b'ould', 465: b'fe', 466: b'ing to ', 467: b'had ', 468: b'do', 469: b'fin', 470: b'?\\n ', 471: b'thing', 472: b'ra', 473: b'were ', 474: b'righ', 475: b'ain', 476: b'su', 477: b'loo', 478: b'\\xe2\\x80\\xa6', 479: b'ther', 480: b'see', 481: b'fu', 482: b'too ', 483: b'al ', 484: b'ce ', 485: b'pro', 486: b'tt', 487: b'ear', 488: b'ang', 489: b'It ', 490: b'No', 491: b'ther ', 492: b'ound ', 493: b'. S', 494: b'as', 495: b'how ', 496: b'lac', 497: b'out', 498: b'our', 499: b'ely ', 500: b'ound', 501: b'up ', 502: b'stil', 503: b'wor', 504: b'did', 505: b'per', 506: b't to ', 507: b'The ', 508: b'ho', 509: b'should ', 510: b'ant', 511: b'use ', 512: b'ever ', 513: b'pre', 514: b'most ', 515: b'no ', 516: b'. A', 517: b'very ', 518: b'I was ', 519: b'know ', 520: b'!\\xe2\\x80\\x9d\\n \\xe2\\x80\\x9c', 521: b'happ', 522: b'feel', 523: b'sp', 524: b'end', 525: b'thin', 526: b'get ', 527: b'ked ', 528: b'.\\xe2\\x80\\x9d\\n ', 529: b'ort', 530: b'way ', 531: b'ud', 532: b'now', 533: b'did ', 534: b'tr', 535: b'didn\\xe2\\x80\\x99t ', 536: b'able ', 537: b'it was ', 538: b'all', 539: b'man', 540: b'fa', 541: b'e\\xe2\\x80\\x99s ', 542: b'ess ', 543: b'still ', 544: b'\\n \\xe2\\x80\\x9c', 545: b'hat\\xe2\\x80\\x99s ', 546: b'much ', 547: b's, ', 548: b'way', 549: b'!\\xe2\\x80\\x9d\\n \\t', 550: b'ever', 551: b'sid', 552: b'ouldn\\xe2\\x80\\x99t ', 553: b'happen', 554: b'again', 555: b'beca', 556: b'par', 557: b'sel', 558: b'de', 559: b'What ', 560: b'they ', 561: b'gi', 562: b'mor', 563: b'it\\xe2\\x80\\x99s ', 564: b'!\\xe2\\x80\\x9d\\n ', 565: b'me to ', 566: b'igh', 567: b'ff', 568: b'int', 569: b'.\\n A', 570: b'prob', 571: b'id ', 572: b'ly, ', 573: b'only ', 574: b'think ', 575: b'by ', 576: b'qu', 577: b'ation', 578: b'pe', 579: b'any', 580: b'tal', 581: b'Wat', 582: b'Watan', 583: b'Watanab', 584: b'time', 585: b'do ', 586: b'low', 587: b'of the ', 588: b'-- ', 589: b'ster', 590: b'p ', 591: b'ation ', 592: b'ut', 593: b'his ', 594: b'box', 595: b'.\\n \\t\\xe2\\x80\\x9c', 596: b'ay ', 597: b'aft', 598: b'go ', 599: b'lea', 600: b'. The ', 601: b'plac', 602: b'could ', 603: b'It\\xe2\\x80\\x99s ', 604: b'something ', 605: b'ell ', 606: b'\\xe2\\x80\\x99ve ', 607: b're ', 608: b'll ', 609: b'Be', 610: b'com', 611: b'\\t\\xe2\\x80\\x9c', 612: b'us', 613: b'we', 614: b', th', 615: b'seem', 616: b'Ne', 617: b'day', 618: b'bac', 619: b'ably ', 620: b'because ', 621: b'.\\n I ', 622: b'say ', 623: b'ite ', 624: b'ment', 625: b'ar ', 626: b'that\\xe2\\x80\\x99s ', 627: b'guess ', 628: b'around ', 629: b'But ', 630: b'ure ', 631: b'or ', 632: b'Wh', 633: b'thought ', 634: b'when ', 635: b'y s', 636: b'right', 637: b'Ha', 638: b'\\xe3\\x81', 639: b'ne', 640: b'i ', 641: b'probably ', 642: b'own ', 643: b'wan', 644: b'ta', 645: b'actu', 646: b'mi', 647: b'I\\xe2\\x80\\x99ve ', 648: b'say', 649: b'ous ', 650: b'going to ', 651: b'one', 652: b'read', 653: b'this', 654: b'You', 655: b'enc', 656: b'uring ', 657: b'in the ', 658: b'ough ', 659: b'who ', 660: b'ul', 661: b'never ', 662: b'in a ', 663: b'really ', 664: b'was', 665: b'ol', 666: b'for a ', 667: b'gr', 668: b'befor', 669: b'ell', 670: b'other ', 671: b'ind ', 672: b'can', 673: b'?\\xe2\\x80\\x9d\\n \\xe2\\x80\\x9c', 674: b'dec', 675: b'mean', 676: b'\\xe2\\x80\\x99re ', 677: b'defin', 678: b'definit', 679: b'My ', 680: b'si', 681: b'loc', 682: b'That ', 683: b'. It\\xe2\\x80\\x99s ', 684: b'op', 685: b'. H', 686: b'seems ', 687: b'anc', 688: b'str', 689: b'star', 690: b'Nez', 691: b'Nezum', 692: b'ap', 693: b'. It ', 694: b'been ', 695: b'my', 696: b'than ', 697: b'na', 698: b'. And ', 699: b'know', 700: b'am', 701: b'come ', 702: b'att', 703: b'et', 704: b'not', 705: b'agic', 706: b'!\\n \\xe2\\x80\\x9c', 707: b'ad ', 708: b'time ', 709: b'stud', 710: b'ir ', 711: b'...', 712: b'a b', 713: b'Not ', 714: b'.\\n \\xe2\\x80\\x9c..', 715: b'ld ', 716: b'der', 717: b'cary s', 718: b'cl', 719: b'poss', 720: b'thr', 721: b'where ', 722: b'fir', 723: b'Watanabe', 724: b'after ', 725: b'choo', 726: b'ose ', 727: b'make ', 728: b'Th', 729: b', she ', 730: b'someone ', 731: b'ach', 732: b'a s', 733: b'? I ', 734: b'r ', 735: b'des', 736: b'ving ', 737: b'fac', 738: b've', 739: b'it, ', 740: b'ate ', 741: b'. She ', 742: b'goo', 743: b'. . ', 744: b'decid', 745: b'ss ', 746: b'more ', 747: b'definitely ', 748: b'right ', 749: b'boo', 750: b'anger', 751: b'?! ', 752: b' s', 753: b'ight', 754: b'Beep', 755: b'cary scary s', 756: b'as if ', 757: b'to be ', 758: b'possi', 759: b'possib', 760: b'I w', 761: b'first ', 762: b'ount', 763: b'day ', 764: b'able to ', 765: b'war', 766: b'want to ', 767: b'too', 768: b'prett', 769: b'pretty ', 770: b'fact', 771: b'I should ', 772: b'me, ', 773: b'look ', 774: b'hal', 775: b'f-', 776: b'pla', 777: b'give ', 778: b'.\\n The ', 779: b'.\\n S', 780: b'own', 781: b'looking ', 782: b'cont', 783: b'e. ', 784: b'conver', 785: b'convers', 786: b'ong', 787: b'ppear', 788: b'I could ', 789: b'mb', 790: b'.\\n And ', 791: b'into ', 792: b'sc', 793: b'ice ', 794: b'\\xe2\\x80\\xa6\\n ', 795: b'any ', 796: b'?!\\xe2\\x80\\x9d\\n \\xe2\\x80\\x9c', 797: b'hey ', 798: b'their ', 799: b'ity ', 800: b'during ', 801: b'Jap', 802: b'schoo', 803: b'ree ', 804: b'ffer', 805: b'those ', 806: b'fri', 807: b'least ', 808: b'back ', 809: b'. In ', 810: b'end ', 811: b'nex', 812: b'ful', 813: b'real', 814: b'about it', 815: b'said ', 816: b'wasn\\xe2\\x80\\x99t ', 817: b'y, ', 818: b'ile ', 819: b'some ', 820: b'lan', 821: b'ps ', 822: b'saying ', 823: b'every', 824: b'ed up ', 825: b'can\\xe2\\x80\\x99t ', 826: b'ed my ', 827: b'our ', 828: b'sure ', 829: b'out of ', 830: b'less ', 831: b'alread', 832: b'got ', 833: b'. N', 834: b'of a ', 835: b'feeling ', 836: b'har', 837: b'..\\xe2\\x80\\x9d\\n ', 838: b'let ', 839: b'would be ', 840: b'. Not ', 841: b'd, ', 842: b'.. I ', 843: b'actually ', 844: b'...\\xe2\\x80\\x9d\\n ', 845: b'h, ', 846: b'That\\xe2\\x80\\x99s ', 847: b'--\\n ', 848: b'hid', 849: b'every ', 850: b'I can ', 851: b'peop', 852: b'side ', 853: b'once ', 854: b'consid', 855: b'ange ', 856: b'encount', 857: b'Japan', 858: b'differ', 859: b'ct', 860: b'. D', 861: b'friend', 862: b'ents ', 863: b'we ', 864: b'start', 865: b'dd', 866: b'as I ', 867: b'lat', 868: b'gett', 869: b'ally, ', 870: b'as a ', 871: b'there\\xe2\\x80\\x99s ', 872: b'. W', 873: b'se, ', 874: b'sound', 875: b', it ', 876: b'ould\\xe2\\x80\\x99ve ', 877: b'pers', 878: b'so, ', 879: b'good ', 880: b'for the ', 881: b'mon', 882: b'now ', 883: b'It was ', 884: b'secon', 885: b'are ', 886: b'mean, ', 887: b'point', 888: b'doing ', 889: b'ice', 890: b'ea', 891: b'gir', 892: b'clo', 893: b'w ', 894: b'hear', 895: b'pic', 896: b'I\\xe2\\x80\\x99d ', 897: b'fel', 898: b'felt ', 899: b'sed ', 900: b'rea', 901: b'cer', 902: b'de ', 903: b'\\xe2\\x80\\x9d ', 904: b'ous', 905: b'ind', 906: b'imag', 907: b'ally', 908: b'h ', 909: b'under', 910: b'one and ', 911: b'ke', 912: b'ect', 913: b'ome', 914: b'ka', 915: b'book', 916: b'You ', 917: b'.. W', 918: b'wal', 919: b'and', 920: b'aa', 921: b'him', 922: b'tel', 923: b'telep', 924: b'box ', 925: b'. They ', 926: b'danger', 927: b'weir', 928: b'ei', 929: b'et ', 930: b'ese ', 931: b'had', 932: b'happened', 933: b'sen', 934: b'part', 935: b'mysel', 936: b'sin', 937: b'couldn\\xe2\\x80\\x99t ', 938: b'. That ', 939: b'same ', 940: b'.\\n \\n ', 941: b'getting ', 942: b'before ', 943: b'at the ', 944: b'pa', 945: b'such ', 946: b'everything ', 947: b'came ', 948: b'ed the ', 949: b'awa', 950: b'there ', 951: b'you\\xe2\\x80\\x99re ', 952: b'down ', 953: b'roo', 954: b'.\\n O', 955: b'ick', 956: b'possible', 957: b'student ', 958: b'fr', 959: b'der ', 960: b'almost ', 961: b'lack ', 962: b'contin', 963: b'continu', 964: b't of ', 965: b'conversation ', 966: b'place ', 967: b'vi', 968: b'quite ', 969: b'opp', 970: b'she was ', 971: b'memb', 972: b'\\xe2\\x80\\xa6\\n \\xe2\\x80\\x9c', 973: b'kind ', 974: b'made ', 975: b'g ', 976: b'here', 977: b'wat', 978: b'care', 979: b'imagin', 980: b'bel', 981: b'beli', 982: b'eve ', 983: b'Yu', 984: b'Yuk', 985: b'making ', 986: b'one and only ', 987: b'gn', 988: b'exp', 989: b'like this', 990: b'Sh', 991: b'Just ', 992: b'over', 993: b'My', 994: b'tur', 995: b'can ', 996: b'disa', 997: b'the h', 998: b'ld', 999: b'ey', 1000: b'*Beep', 1001: b'teleport', 1002: b'..\\n \\t\\xe2\\x80\\x9c', 1003: b'!\\xe2\\x80\\x9d\\n \\t\\xe2\\x80\\x9c', 1004: b'!\\n \\t\\xe2\\x80\\x9c', 1005: b'location', 1006: b'wol', 1007: b'ster ', 1008: b'weird ', 1009: b'. It\\xe2\\x80\\x99s not ', 1010: b'I didn\\xe2\\x80\\x99t ', 1011: b'ence ', 1012: b', there ', 1013: b'stanc', 1014: b'If ', 1015: b'Nezumi ', 1016: b'different ', 1017: b'mean ', 1018: b', I was ', 1019: b'went ', 1020: b'through ', 1021: b'at least ', 1022: b'ed it ', 1023: b'Nezumi'}\n"
     ]
    }
   ],
   "source": [
    "vocab = tokenizer.vocab\n",
    "\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[559, 396]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"What the\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xstill ï¿½L'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([120, 543, 222, 76])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking pretty spicy.\n",
    "\n",
    "Let's also append some special tokens to the vocab.\n",
    "\n",
    "This will be useful for training later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_id = list(vocab.keys())[-1]\n",
    "tokenizer.special_tokens = {\n",
    "    max_vocab_id + 1: \"<<startoftext>>\",\n",
    "    max_vocab_id + 2: \"<<separator>>\",\n",
    "    max_vocab_id + 3: \"<<endoftext>>\",\n",
    "    max_vocab_id + 4: \"<<unk>>\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15625"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.encode(text_sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save(file_prefix=\"./output/tokenizer/da_tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Model\n",
    "\n",
    "We will need both an encoder and a decoder.\n",
    "\n",
    "A decoder will consist of the following components:\n",
    "    - token embedding (represent a token with a vector)\n",
    "    - positional encoding (preserving token orders)\n",
    "    - self attention (keep track of relation between tokens)\n",
    "    - residual connections\n",
    "    - layer normalization\n",
    "\n",
    "Parameters of a decoder:\n",
    "- block size\n",
    "- embedding size\n",
    "- number of heads & head size\n",
    "- number of blocks (layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_size(tokenizer: BasicTokenizer) -> int:\n",
    "    vocab = tokenizer.vocab\n",
    "    special_tokens = tokenizer.special_tokens\n",
    "\n",
    "    return len(vocab) + len(special_tokens)\n",
    "\n",
    "def print_model_structure(model: torch.nn.Module, indent: str = '') -> None:\n",
    "    for name, child in model.named_children():\n",
    "        params = sum(p.numel() for p in child.parameters())\n",
    "        print(f\"{indent}|-- {name}: {child.__class__.__name__} ({params:,} parameters)\")\n",
    "        print_model_structure(child, indent + '|    ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "blockSize = 256\n",
    "embedSize = 384\n",
    "headCount = 6\n",
    "layerCount = 6\n",
    "dropout = 0.2\n",
    "batchSize = 128\n",
    "vocabSize = get_vocab_size(tokenizer)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.529476 M params\n"
     ]
    }
   ],
   "source": [
    "model = GPTLanguageModel(\n",
    "    vocab_size=vocabSize,\n",
    "    block_size=blockSize,\n",
    "    n_embd=embedSize,\n",
    "    n_head=headCount,\n",
    "    n_layer=layerCount,\n",
    "    dropout=dropout,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_model_structure(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15625"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text_sequence = tokenizer.encode(text_sequence)\n",
    "len(encoded_text_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(encoded_text_sequence, dtype=torch.long)\n",
    "split_index = int(0.9 * len(data))\n",
    "train_data = data[:split_index]\n",
    "val_data = data[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data: torch.Tensor, block_size: int) -> None:\n",
    "        self.data = data\n",
    "        self.block_size = block_size\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data) - self.block_size\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        x = self.data[index:index + self.block_size]\n",
    "        y = self.data[index + 1:index + self.block_size + 1]\n",
    "\n",
    "        return x, y\n",
    "\n",
    "def get_dataloaders(\n",
    "    train_data: torch.Tensor,\n",
    "    val_data: torch.Tensor,\n",
    "    block_size: int,\n",
    "    batch_size: int,\n",
    "    device: torch.device\n",
    ") -> Tuple[DataLoader, DataLoader]:\n",
    "    train_dataset = TextDataset(train_data.to(device), block_size)\n",
    "    val_dataset = TextDataset(val_data.to(device), block_size)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 256]), torch.Size([128, 256]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader, val_loader = get_dataloaders(\n",
    "    train_data=train_data,\n",
    "    val_data=val_data,\n",
    "    block_size=blockSize,\n",
    "    batch_size=batchSize,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "x, y = next(iter(train_loader))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss(\n",
    "    model: torch.nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    eval_iters: int\n",
    ") -> Dict[str, float]:\n",
    "    output = {}\n",
    "    model.eval()\n",
    "\n",
    "    for split, loader in [('train', train_loader), ('val', val_loader)]:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for i, (x, y) in enumerate(loader):\n",
    "            if i >= eval_iters:\n",
    "                break\n",
    "            with torch.no_grad():\n",
    "                _, loss = model(x, y)\n",
    "            losses[i] = loss.item()\n",
    "        output[split] = losses.mean().item()\n",
    "\n",
    "    model.train()\n",
    "    return output\n",
    "\n",
    "def save_checkpoint(\n",
    "    model: GPTLanguageModel,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    epoch: int,\n",
    "    loss: float,\n",
    "    filename: str = \"checkpoint.pth\"\n",
    ") -> None:\n",
    "    checkpoint = {\n",
    "        'epoch' : epoch,\n",
    "        'model_state_dict' : model.state_dict(),\n",
    "        'optimizer_state_dict' : optimizer.state_dict(),\n",
    "        'loss' : loss\n",
    "    }\n",
    "\n",
    "    torch.save(checkpoint, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = 2\n",
    "eval_interval = 10\n",
    "eval_iters = 200\n",
    "learning_rate = 1e-4\n",
    "save_interval = 5\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "train_loader, val_loader = get_dataloaders(\n",
    "    train_data=train_data,\n",
    "    val_data=val_data,\n",
    "    block_size=blockSize,\n",
    "    batch_size=batchSize,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration in range(max_iters):\n",
    "    for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        if batch_idx % eval_interval == 0 or batch_idx == len(train_loader) - 1:\n",
    "            losses = estimate_loss(\n",
    "                model=model,\n",
    "                train_loader=train_loader,\n",
    "                val_loader=val_loader,\n",
    "                eval_iters=min(eval_iters, len(val_loader))\n",
    "            )\n",
    "\n",
    "            train_losses.append(losses['train'])\n",
    "            val_losses.append(losses['val'])\n",
    "\n",
    "            print(\n",
    "                f\"iteration {iteration} / step {batch_idx}: \"\n",
    "                f\"train loss {losses['train']:.4f}, \"\n",
    "                f\"val loss {losses['val']:.4f}\"\n",
    "            )\n",
    "\n",
    "            logits, loss = model(x_batch, y_batch)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if iteration % save_interval == 0:\n",
    "            save_checkpoint(\n",
    "                model=model,\n",
    "                optimizer=optimizer,\n",
    "                epoch=iteration,\n",
    "                loss=loss.item(),\n",
    "                filename=f\"./output/pre_training/checkpoint_{iteration}.pth\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Eval Step\")\n",
    "plt.ylim(0)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Eval Loss Over Time\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
